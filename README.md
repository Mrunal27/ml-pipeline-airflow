# ğŸ§  Modular ML Pipeline with Airflow & Docker

This project demonstrates a reproducible machine learning pipeline orchestrated using Apache Airflow and Docker. It includes modular tasks for data preparation, model training, and evaluationâ€”designed to reflect scalable backend workflows and infrastructure reliability.

---

## ğŸš€ Pipeline Overview

This ML pipeline automates the following stages:

- **Data Preparation** (`prepare_dataset.py`)  
  Loads and preprocesses housing data for training.

- **Model Training** (`train.py`)  
  Trains a regression model using scikit-learn and saves it as `model.pkl`.

- **Model Evaluation** (`evaluate.py`)  
  Computes evaluation metrics (e.g., Mean Squared Error) on the trained model.

The pipeline is orchestrated via an Airflow DAG (`ml_pipeline_dag.py`) using `PythonOperator`, with the following task flow:

```text
[prepare_dataset] â†’ [train_model] â†’ [evaluate_model]

## ğŸ§° Tech Stack

| Layer            | Tools Used               |
|------------------|--------------------------|
| Orchestration    | Apache Airflow           |
| Containerization | Docker, docker-compose   |
| ML Framework     | Scikit-learn, Pandas     |
| Language         | Python                   |

ğŸ› ï¸ Infrastructure Details
- Airflow 3.x deployed via Docker Compose
- PostgreSQL & Redis services for metadata and caching
- .env file for UID/GID mapping (Windows compatibility)

ğŸ“¦ Setup Instructions
Clone the repo and launch the pipeline:

git clone https://github.com/yourusername/ml-airflow-pipeline.git
cd ml-airflow-pipeline
docker-compose up --build

ğŸ“ˆ Sample Output
- Trained model saved as model.pkl
- Evaluation metrics printed in logs (e.g., MSE: 0.032)
- DAG visualized in Airflow UI with task status tracking

ğŸ” Reliability & Validation
- Modular task design for reproducibility and testability
- Dockerized environment ensures consistent execution
- Logging and output validation built into each stage
- .env integration for cross-platform compatibility

ğŸ’¡ Why This Project?
This pipeline was built to showcase backend orchestration and infrastructure skills as part of my pivot from SDET into ML Infra and platform engineering. It reflects my focus on modular design, reproducible workflows, and system reliability.

ğŸ”­ Future Enhancements
- Add CI/CD integration with GitHub Actions
- Integrate model registry (e.g., MLflow)
- Wrap model inference in FastAPI for API deployment
- Add unit tests and DAG-level validation hooks

ğŸ‘¤ Author
Mrunal

ğŸ“„ License
This project is licensed under the MIT License.

---
_#MachineLearning #Airflow #Docker #BackendEngineering #CareerPivot #OpenToWork_
